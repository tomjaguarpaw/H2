# AI doom posterity

Will these AI doomers be proved right?  Only time will tell (or
won't)!

> the more I look at the LLM revolution the more worried I am that we
> should be counting in months rather than years

-- [Roko
Mijic](https://twitter.com/RokoMijic/status/1643959006040293377),
2023-04-06

> I've unfortunately updated towards the singularity happening
> sooner. ~2030 say.

-- [Roko
Mijic](https://twitter.com/RokoMijic/status/1642659846716633089),
2023-04-02

> we just had a little baby, and I keep asking myself... how old is he
> even gonna get?

-- [Max
Tegmark](https://twitter.com/liron/status/1648185583938969600),
2023-04-18

> As bad as climate change is, AI is likely to get us first I think -
> we may only have 2-5 years (vs 20-50 with climate). We need to slam
> the brakes on AGI development now.

-- [Greg
Colbourn](https://twitter.com/gcolbourn/status/1648267236019167232),
2023-04-18

> I'm willing to bet we'll reach 30% unemployment in five years.

--
[TheDag](https://www.themotte.org/post/440/culture-war-roundup-for-the-week/87511?context=8#context),
2023-04-15

> If we go back to things like the bio weapons or cyber [attacks], you
> can have really very dangerous threats to humans that could kill
> many humans – not all humans – simply from where we would expect
> models to be in two years’ time.

-- [Matt
Clifford](https://www.independent.co.uk/news/uk/politics/ai-artificial-intelligence-kill-humans-sunak-b2352099.html),
2023-06-06

> The top scientists at the biggest AI firms believe that they can
> make artificial intelligence a billion times more powerful than
> today’s most advanced models, creating “something like a god” within
> five years

-- [Daniel
Colson](https://twitter.com/DanielColson6/status/1691598172513296710)
2023-08-16

## Non-doom

> AGI will absolutely be achieved in AT MOST 3 years. Probably less. I
> guarantee. And it will be able to write any imaginable software
> faster than the fastest human dev team in the world could, for
> pennies.

-- [Victor
Taelin](https://twitter.com/VictorTaelin/status/1747674769342738587),
2024-01-17

> There is a 4%-20% chance of "straight up catastrophe" during 2024.

-- A conclusion from a survey by [Edouard
Harris](https://twitter.com/NickEMoran/status/1767247012825571776)

## AI notes

* Yudkowsky can't make predictions about what the trajectory to AI
  doom will look like because one can only know the end state not the
  trajectory, yet he claims that the trajectory in the last two
  decades is evidence that we're converging on the end state.

  <https://twitter.com/dwarkesh_sp/status/1643986757174837252>

  <https://twitter.com/liron/status/1646301141196742656>
